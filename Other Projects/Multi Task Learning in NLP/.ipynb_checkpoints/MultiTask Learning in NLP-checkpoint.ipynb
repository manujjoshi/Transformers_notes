{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aed6a7a",
   "metadata": {},
   "source": [
    "# [Blog KDNuggets](https://www.kdnuggets.com/2019/10/multi-task-learning-ernie-sota-nlp-architecture.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087ad4e4",
   "metadata": {},
   "source": [
    "## ERNIE 2.0 trains its neural network to perform 7 tasks which will be explained in more detail.\n",
    "# [Medium Blog](https://medium.com/analytics-vidhya/a-primer-on-multi-task-learning-in-nlp-part-1-7154b4227c0e)\n",
    "# [Kaggle](https://www.kaggle.com/code/haithemhermessi/nlp-multi-task-learning-with-transformers/notebook)\n",
    "# [TDS Blog](https://towardsdatascience.com/hmtl-multi-task-learning-for-solving-nlp-tasks-cfae39b3d6e1)\n",
    "# [GITHUB Repo](https://github.com/truongnmt/multi-task-learning)\n",
    "# [GITHUB multiTask List](https://github.com/Manchery/awesome-multi-task-learning)\n",
    "# [Colab Notebook on multi tasking](https://colab.research.google.com/github/zphang/zphang.github.io/blob/master/files/notebooks/Multi_task_Training_with_Transformers_NLP.ipynb#scrollTo=CQ39AbTAPAUi)\n",
    "\n",
    "# [Loading Dataset nlp](https://huggingface.co/docs/datasets/v0.4.0/loading_datasets.html)\n",
    "# [Data](https://gist.github.com/raffaem/bcd8e1c21339408cd477b6798e7d6133)\n",
    "# [Medium Blog](https://medium.com/analytics-vidhya/a-primer-on-multi-task-learning-in-nlp-part-1-7154b4227c0e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763a3d14",
   "metadata": {},
   "source": [
    "# `Integration Function of Customer Analytics to extract data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2648dba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docx\n",
    "\n",
    "def conv_stamp_secs(ti):\n",
    "    time, ms = ti.split(\".\")\n",
    "    hr, mins, secs = time.split(\":\")\n",
    "    secs = str(int(hr)*3600 + int(mins)*60 + int(secs)) + '.' + ms\n",
    "    return float(secs)\n",
    "def extract_text(doc_text_with_ts):\n",
    "    text = []\n",
    "    for i in doc_text_with_ts:\n",
    "        text.append(f\"{i[0]}: {i[2]}\")\n",
    "    return preprocess(' '.join(map(str, text)))\n",
    "def split_speakers(text):\n",
    "    lines = text.split(\":\")\n",
    "    prevline = lines[0]\n",
    "    speaker_trans = {}\n",
    "\n",
    "    for each_line in lines[1:]:\n",
    "        speaker = prevline.split(\" \")[-1].lower()\n",
    "        line = \" \".join(each_line.split(\" \")[:-1]).strip()\n",
    "        if speaker not in speaker_trans:\n",
    "            speaker_trans[speaker] = [line]\n",
    "        else:\n",
    "            speaker_trans[speaker].append(line)\n",
    "        prevline = each_line\n",
    "    return speaker_trans\n",
    "def preprocess(text):\n",
    "    text = text.replace(\"Kashetti Prashanth\", \"Prashanth\").replace(\"Manuj Kumar Joshi\", \"Manuj\")\n",
    "    return text\n",
    "\n",
    "def process_timestamp(ts):\n",
    "    start, end = ts.split(\" --> \")\n",
    "    conv_stamp_secs(start), conv_stamp_secs(end)\n",
    "    return [conv_stamp_secs(start), conv_stamp_secs(end)]\n",
    "\n",
    "def preprocess_transcript(doc_path):\n",
    "    doc = docx.Document(doc_path)\n",
    "    speakers = []\n",
    "    resp = []\n",
    "    new_paras = [p.text for p in doc.paragraphs if p.text]\n",
    "    speaker_map = {'Agent': None, 'Customer': None}\n",
    "    for n,i in enumerate(new_paras):\n",
    "        a = i.split('\\n')\n",
    "        if n==0:\n",
    "            speaker_map['Agent'] = a[1]\n",
    "            \n",
    "        new_paras_better = f\"{a[2]}\".replace(\"Kashetti Prashanth\", \"Prashanth\").replace(\"Manuj Kumar Joshi\", \"Manuj\")\n",
    "        resp.append([ a[1], process_timestamp(a[0]), new_paras_better])\n",
    "        \n",
    "    return resp, speaker_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07e60e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate(file):\n",
    "    doc_text_with_ts, speaker_map = preprocess_transcript(file)\n",
    "    txt = extract_text(doc_text_with_ts)\n",
    "    bot = list(split_speakers(txt).keys())[0]\n",
    "    customer = list(split_speakers(txt).keys())[1]\n",
    "    bot = split_speakers(txt)[bot]\n",
    "    customer = split_speakers(txt)[customer]\n",
    "    bot = ''.join(bot)\n",
    "    customer = ''.join(customer)\n",
    "    return {\"BOT\":bot,\"CUSTOMER\":customer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "491759f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOT': \"Hello everyone this IVR automation for banking is powered by sellable technologies.Hi I'm Prashanth calling you from syllable tech bank. We have an EMI offer specially created for you. Do you want to know more about this offer?This call is being recorded by syllable tech Bank. Please do not share your CVV and OTP with anyone.As I can see in this case a transaction of 30,000 was done on Snapdeal. Do you want to convert this into EMI?What type of loan?Did you need?How much will you need for this loan?I have logged your details.Our customer service representative will contact you soon.Keep banking with sellable tech bank. Thank you.\",\n",
       " 'CUSTOMER': 'Hi.Yes, go on.I want a loan.But a personal loan.I need 10 Lac rupees.Thank you very'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrate('21.docx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fea141",
   "metadata": {},
   "source": [
    "# `Loading model from .bin file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dab1822",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
