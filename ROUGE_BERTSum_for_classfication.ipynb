{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ROUGE BERTSum for classfication.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## [BERT, RoBERTa, DistilBERT, XLNet: Which one to use ? KDnuggets blog](https://www.kdnuggets.com/2019/09/bert-roberta-distilbert-xlnet-one-use.html)\n",
        "\n",
        "# **BERTSUM for Text Summarization**\n",
        "- Text summarization is one of the most popular applications of natural language processing.\n",
        "In this chapter, we will understand how to fine-tune the pre-trained BERT model for a text\n",
        "summarization task. The BERT model fine-tuned for the text summarization task is often\n",
        "called **BERTSUM (BERT for summarization)**.\n",
        "## **Topics Covered**\n",
        "- Text summarization\n",
        "- Fine-tuning BERT for text summarization\n",
        "- Extractive summarization using BERT\n",
        "- Abstractive summarization using BERT\n",
        "- Understanding ROUGE evaluation metrics \n",
        "- The performance of the BERTSUM model\n",
        "- Training the BERTSUM model \n",
        "## **Text Summarization is of two types**\n",
        "- **Extractive summarization**\n",
        "  - In extractive summarization, we create a summary from a given text by extracting only the\n",
        "important sentences. \n",
        "  - That is, say we are given a long document containing many sentences, with extractive\n",
        "summarization, we create a summary of the document by extracting only the important\n",
        "sentences that hold the essential meaning of the document. \n",
        "- **Abstractive summarization**\n",
        "  - Unlike extractive summarization, in abstractive summarization, we will not create a\n",
        "summary by just extracting important sentences from the given text. Instead, in this type,\n",
        "we create a summary by paraphrasing the given text. Okay, what is paraphrasing?\n",
        "Paraphrasing implies that we re-express the given text using different words to provide\n",
        "more clarity.\n",
        "  - So, in abstractive summarization, given a text, we will create a summary by re-expressing\n",
        "the given text using different words holding only the essential meaning of the given text. \n",
        "Let's understand abstractive summarization with a small example. Let's consider the sam\n",
        "\n",
        "## **Understanding ROUGE evaluation metrics**\n",
        "- In order to evaluate a text summarization task, we use a popular set of metrics called\n",
        "ROUGE, which stands for Recall-Oriented Understudy for Gisting Evaluation. First, we\n",
        "will understand how the ROUGE metric works, and then we will check the ROUGE score\n",
        "for text summarization with the BERTSUM model. \n",
        "- The ROUGE metric was first introduced in the paper ROUGE: A Package for Automatic\n",
        "Evaluation of Summaries by Chin-Yew Lin. The five different ROUGE evaluation metrics\n",
        "include the following: \n",
        "  - ROUGE-N\n",
        "  - ROUGE-L\n",
        "  - ROUGE-W\n",
        "  - ROUGE-S\n",
        "  - ROUGE-SU\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "sDrRJWC8HV1k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "aV4rPiyRHWE3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}